{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PssGhsXXdTXZ"
      },
      "outputs": [],
      "source": [
        "#Implement logistic regression with L2 norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EFeWOwidTXd"
      },
      "source": [
        "![title](https://github.com/chloebittiger/UdemyMachineLearning/blob/master/Module%201/livecoding/gradient.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xL2DFOTHdTXe"
      },
      "outputs": [],
      "source": [
        "# y_i(1-y_i_hat)-(1-y_i)y_i_hat \n",
        "\n",
        "# y_i-y_i_hat, y_i=1 or 0\n",
        "\n",
        "# the gradient of CE is just (y_i-y_i_hat)*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PEkg7Wc_dTXf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class twoClassLogisticRegression():\n",
        "    def __init__(self, lbda=1., tol=0.001, alpha=0.1):\n",
        "        # __init__ is a function (constructor) called when somebody write \n",
        "        # myModel = twoClassLogisticRegression(lbda=0.5) (1/C)\n",
        "        self.lbda = lbda #regularizer penalty\n",
        "        self.tol = tol #tolerance\n",
        "        self.alpha = alpha #learning rate\n",
        "    \n",
        "    def logistic(self, u):\n",
        "        # u is the linear function of features\n",
        "        # u = w0 + w1*x1 + w2*x2 ... \n",
        "        return 1./(1.+ np.exp(-u)) \n",
        "    \n",
        "    def fit(self, X, Y):\n",
        "        # model training\n",
        "        # X is the design matrix with the shape N by p\n",
        "        # y is the response as a 1-d array e.g. [0,1,1,0,1...]\n",
        "        N = X.shape[0]\n",
        "        p = X.shape[1]\n",
        "        self._class = np.unique(Y) # list all class labels e.g. [\"A\",\"B\"]\n",
        "        assert(len(self._class)==2)\n",
        "        self._class.sort()\n",
        "        self._class = list(self._class)\n",
        "        print (\"class labels: \", self._class)\n",
        "        Y_label = np.array([self._class.index(y) for y in Y]) # now Y_label is 1 or 0 for sure\n",
        "        Y_label = Y_label[:, np.newaxis] #transform Y_label to be a column vector\n",
        "        \n",
        "        # Y_label is column vector of 0 or 1\n",
        "        \n",
        "        #initialize weights, also use a bias constant, u = w0 + w1x1 + w2x2 ... \n",
        "        w_old = np.random.randn(p,1) # w1...wp, normal distribution\n",
        "        w0_old = np.random.randn(1) # w0, normal distribution\n",
        "    \n",
        "        while(True):\n",
        "            Y_hat = self.logistic(np.dot(X, w_old) + w0_old) #make prediction\n",
        "            g_w = -((Y_label - Y_hat) * X).mean(axis=0)[:,np.newaxis] + self.lbda * w_old \n",
        "            #[:, np.newaxis] to make 1-d vector to 2-d column vector\n",
        "            g_w0 = -(Y_label - Y_hat).mean(axis=0)\n",
        "            # steepest gradient descent\n",
        "            w_new = w_old - self.alpha * g_w\n",
        "            w0_new = w0_old - self.alpha * g_w0\n",
        "            if(((w_old - w_new)**2).sum() < self.tol):\n",
        "                print (\"the algorithm has converged\")\n",
        "                break\n",
        "            w_old = w_new\n",
        "            w0_old = w0_new\n",
        "            \n",
        "        self.w = w_new\n",
        "        self.w0 = w0_new\n",
        "        \n",
        "    def predict_prob(self, X):\n",
        "        return self.logistic(np.dot(X, self.w)+ self.w0)\n",
        "\n",
        "    def predict(self,X):\n",
        "        probs = self.predict_prob(X)\n",
        "        labels = [1 if x>0.5 else 0 for x in probs] #using list comprehension, threshold set to be 0.5\n",
        "        return [self._class[label] for label in labels]   \n",
        "    \n",
        "    def score(self, X, Y):\n",
        "        Y_pred = self.predict(X)\n",
        "        accuracy = np.mean(Y == Y_pred)\n",
        "        return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qmgPhUzrdTXg"
      },
      "outputs": [],
      "source": [
        "model = twoClassLogisticRegression() # compare to sklearn logisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7B-oPrWdTXg",
        "outputId": "c8eeca82-3843-4c34-9498-2aab1d072801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n",
            "[1.41272917e+01 1.92896485e+01 9.19690334e+01 6.54889104e+02\n",
            " 9.63602812e-02 1.04340984e-01 8.87993158e-02 4.89191459e-02\n",
            " 1.81161863e-01 6.27976098e-02 4.05172056e-01 1.21685343e+00\n",
            " 2.86605923e+00 4.03370791e+01 7.04097891e-03 2.54781388e-02\n",
            " 3.18937163e-02 1.17961371e-02 2.05422988e-02 3.79490387e-03\n",
            " 1.62691898e+01 2.56772232e+01 1.07261213e+02 8.80583128e+02\n",
            " 1.32368594e-01 2.54265044e-01 2.72188483e-01 1.14606223e-01\n",
            " 2.90075571e-01 8.39458172e-02]\n",
            "[-3.16286735e-15 -6.53060890e-15 -7.07889127e-16 -8.79983452e-16\n",
            "  6.13217737e-15 -1.12036918e-15 -4.42138027e-16  9.73249991e-16\n",
            " -1.97167024e-15 -1.45363120e-15 -9.07641468e-16 -8.85349205e-16\n",
            "  1.77367396e-15 -8.29155139e-16 -7.54180940e-16 -3.92187747e-16\n",
            "  7.91789988e-16 -2.73946068e-16 -3.10823423e-16 -3.36676596e-16\n",
            " -2.33322442e-15  1.76367415e-15 -1.19802625e-15  5.04966114e-16\n",
            " -5.21317026e-15 -2.17478837e-15  6.85645643e-16 -1.41265636e-16\n",
            " -2.28956670e-15  2.57517109e-15]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "Y = data.target\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(X.mean(axis=0)) # compute every feature's mean\n",
        "\n",
        "\n",
        "# preprocessing standardization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X) # standardization\n",
        "print(X.mean(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCAZEcnedTXi",
        "outputId": "7ed77df4-b319-4fe4-b445-09d8c9cd87bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class labels:  [0, 1]\n",
            "the algorithm has converged\n"
          ]
        }
      ],
      "source": [
        "model.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcC9tgnfdTXi",
        "outputId": "ed2344cc-d9ec-41a3-e613-f87670e70363"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9191564147627417"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.score(X, Y) #training accuracy"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}